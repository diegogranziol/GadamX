{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/home/dgranziol/kfac-curvature\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Older torchvision found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/dgranziol/anaconda2/envs/newtensor/lib/python3.7/site-packages/torchvision/transforms/transforms.py:396: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import tabulate\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gpytorch.utils.lanczos import lanczos_tridiag\n",
    "\n",
    "import torch\n",
    "\n",
    "from curvature import data, models, losses, utils\n",
    "from curvature.methods.swag import SWAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model Logistic\n"
     ]
    }
   ],
   "source": [
    "dataset = 'MNIST'\n",
    "data_path = '/nfs/home/dgranziol/kfac-curvature/data'\n",
    "#LOGISTIC REGRESSION MNIST\n",
    "ckpt = '/nfs/home/dgranziol/kfac-curvature/out/MNIST/Logistic/SGD/seed=1_lr=0.01_mom=0.9_wd=0.0_numepochs=1000/checkpoint-01000.pt'\n",
    "\n",
    "dataset = ckpt.split('/out/')[1].split('/')[0]\n",
    "model = ckpt.split('/seed=')[0].split('/')[7]\n",
    "network = model\n",
    "epochsave = int(ckpt.split('checkpoint-')[1].split('.')[0])\n",
    "\n",
    "# #MLP small MNIST\n",
    "# ckpt = '/nfs/home/dgranziol/kfac-curvature/out/MNIST/MLP_sdp/SGD/seed=1_lr=0.03_mom=0.9_wd=0.0_batchsize=128_numepochs=200/checkpoint-00200.pt'\n",
    "\n",
    "\n",
    "#model = 'Logistic'\n",
    "print('Using model %s' % model)\n",
    "#from curvature.models import logistic_regression\n",
    "model_cfg = getattr(models,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST from /nfs/home/dgranziol/kfac-curvature/data\n",
      "You are going to run models on the test set. Are you sure?\n",
      "Using train (60000) + test (10000)\n",
      "Loading MNIST from /nfs/home/dgranziol/kfac-curvature/data\n",
      "You are going to run models on the test set. Are you sure?\n",
      "Using train (60000) + test (10000)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "\n",
    "datasets, num_classes = data.datasets(\n",
    "    dataset,\n",
    "    data_path,\n",
    "    transform_train=model_cfg.transform_test,\n",
    "    transform_test=model_cfg.transform_test,\n",
    "    use_validation=False,\n",
    "    train_subset=None,\n",
    "    train_subset_seed=None,\n",
    ")\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    datasets['train'],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "full_datasets, _ = data.datasets(\n",
    "    dataset,\n",
    "    data_path,\n",
    "    transform_train=model_cfg.transform_train,\n",
    "    transform_test=model_cfg.transform_test,\n",
    "    use_validation=False,\n",
    ")\n",
    "full_loader = torch.utils.data.DataLoader(\n",
    "    full_datasets['train'],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /nfs/home/dgranziol/kfac-curvature/out/MNIST/Logistic/SGD/seed=1_lr=0.01_mom=0.9_wd=0.0_numepochs=1000/checkpoint-01000.pt\n"
     ]
    }
   ],
   "source": [
    "model = model_cfg.base(*model_cfg.args, num_classes=num_classes, **model_cfg.kwargs)\n",
    "print('Loading %s' % ckpt)\n",
    "checkpoint = torch.load(ckpt)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "num_parametrs = sum([p.numel() for p in model.parameters()])\n",
    "criterion = losses.cross_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0162, grad_fn=<MulBackward0>)\n",
      "tensor(0.0174, grad_fn=<MulBackward0>)\n",
      "tensor(0.0192, grad_fn=<MulBackward0>)\n",
      "tensor(0.0159, grad_fn=<MulBackward0>)\n",
      "tensor(0.0181, grad_fn=<MulBackward0>)\n",
      "tensor(0.0174, grad_fn=<MulBackward0>)\n",
      "tensor(0.0183, grad_fn=<MulBackward0>)\n",
      "tensor(0.0192, grad_fn=<MulBackward0>)\n",
      "tensor(0.0180, grad_fn=<MulBackward0>)\n",
      "tensor(0.0186, grad_fn=<MulBackward0>)\n",
      "tensor(0.0180, grad_fn=<MulBackward0>)\n",
      "tensor(0.0201, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f171b63cc80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/nfs/home/dgranziol/anaconda2/envs/newtensor/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/nfs/home/dgranziol/anaconda2/envs/newtensor/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 893, in _shutdown_workers\n",
      "    self.worker_result_queue.put((None, None))\n",
      "  File \"/nfs/home/dgranziol/anaconda2/envs/newtensor/lib/python3.7/multiprocessing/queues.py\", line 87, in put\n",
      "    self._start_thread()\n",
      "  File \"/nfs/home/dgranziol/anaconda2/envs/newtensor/lib/python3.7/multiprocessing/queues.py\", line 170, in _start_thread\n",
      "    self._thread.start()\n",
      "  File \"/nfs/home/dgranziol/anaconda2/envs/newtensor/lib/python3.7/threading.py\", line 847, in start\n",
      "    _start_new_thread(self._bootstrap, ())\n",
      "RuntimeError: can't start new thread\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 24702) is killed by signal: Killed. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6241a7d8bc01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_parametrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#grad_list2 = torch.autograd.grad(grad_i[i], model.parameters(), create_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/newtensor/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    147\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/newtensor/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 24702) is killed by signal: Killed. "
     ]
    }
   ],
   "source": [
    "#getting the full Hessian\n",
    "model.zero_grad()\n",
    "N = len(loader.dataset)\n",
    "a = torch.zeros(num_parametrs,num_parametrs).cpu()\n",
    "for input, target in full_loader:\n",
    "    #input = input.cuda(non_blocking=True)\n",
    "    #target = target.cuda(non_blocking=True)\n",
    "    loss, _, _ = criterion(model, input, target)\n",
    "    loss *= input.size()[0] / N\n",
    "    print(loss)\n",
    "    #loss.backward(retain_graph=True)\n",
    "    #loss.backward()\n",
    "    grad_list = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
    "    grad_i = torch.cat([g.view(-1) for g in grad_list]).cpu()\n",
    "    for i in range(0,num_parametrs):\n",
    "        #grad_list2 = torch.autograd.grad(grad_i[i], model.parameters(), create_graph=True)\n",
    "        a[i] = torch.cat([g.view(-1) for g in torch.autograd.grad(grad_i[i], model.parameters(), create_graph=True)]).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = a.detach().numpy()\n",
    "C = np.linalg.svd(matrix, full_matrices=True)\n",
    "print(C[1][0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "sio.savemat('matrix_'+dataset+'_'+network+'_'+str(epochsave)+'.mat', {'matrix':matrix})\n",
    "\n",
    "print('matrix_'+dataset+'_'+network+'_'+str(epochsave)+'.mat saved')\n",
    "\n",
    "import matplotlib\n",
    "#ax = sns.heatmap(matrix, yticklabels=2, xticklabels=False)\n",
    "#uniform_data = np.random.rand(10000, 10000)\n",
    "plt.imshow(matrix)\n",
    "cax = plt.axes([0.85, 0.1, 0.075, 0.8])\n",
    "plt.colorbar(cax=cax)\n",
    "plt.savefig('matrix_'+dataset+'_'+network+'_'+str(epochsave)+'.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eigenvalue distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=C[1], bins=10000, color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.001)\n",
    "# plt.grid(axis='y', alpha=0.75)\n",
    "# plt.xlabel('Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('My Very Own Histogram')\n",
    "# plt.text(23, 45, r'$\\mu=15, b=3$')\n",
    "# maxfreq = n.max()\n",
    "# # Set a clean upper y-axis limit.\n",
    "# plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "threshold = 1e-4\n",
    "for i in range(0,len(C[1])):\n",
    "    if C[1][i] < threshold:\n",
    "        counter = counter+1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[max(a) for a in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurvVecProduct(object):\n",
    "    def __init__(self, loader, model, criterion, curvature_matrix, full_loader=None):\n",
    "        self.loader = loader\n",
    "        self.full_loader = full_loader\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.iters = 0\n",
    "        self.timestamp = time.time()\n",
    "        self.curvature_matrix = curvature_matrix\n",
    "\n",
    "    def __call__(self, vector):\n",
    "        start_time = time.time()\n",
    "        if self.curvature_matrix == 'hessian':\n",
    "            output = utils.hess_vec(\n",
    "                vector,\n",
    "                self.loader,\n",
    "                self.model,\n",
    "                self.criterion,\n",
    "                cuda='cuda'\n",
    "               \n",
    "                )\n",
    "        elif self.curvature_matrix == 'covgrad':\n",
    "            output = utils.covgrad_vec(\n",
    "                vector,\n",
    "                self.loader,\n",
    "                self.model,\n",
    "                self.criterion,\n",
    "                cuda='cuda',\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognised curvature_matrix argument \"+self.curvature_matrix)\n",
    "        time_diff = time.time() - start_time\n",
    "\n",
    "        self.iters += 1\n",
    "        print('Iter %d. Time: %.2f' % (self.iters, time_diff))\n",
    "        # return output.unsqueeze(1)Â¬\n",
    "        return output.cpu().unsqueeze(1)\n",
    "\n",
    "w = torch.cat([param.detach().cpu().view(-1) for param in model.parameters()])\n",
    "w_l2_norm = torch.norm(w).numpy()\n",
    "w_linf_norm = torch.norm(w, float('inf')).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hessian\n",
    "productor = CurvVecProduct(full_loader, model, criterion, 'hessian')\n",
    "#utils.bn_update(loader, model)\n",
    "Q, T = lanczos_tridiag(productor, 15, dtype=torch.float32, device='cpu', matrix_shape=(num_parametrs, num_parametrs))\n",
    "\n",
    "eigvals, eigvects = T.eig(eigenvectors=True)\n",
    "gammas = eigvects[0, :] ** 2\n",
    "V = eigvects.t() @ Q.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigval = []\n",
    "for i in range(0,len(eigvals)):\n",
    "    eigval.append(eigvals[i][0])\n",
    "mean = np.dot(eigval,gammas)\n",
    "print(mean)\n",
    "eigval, gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = utils.grad(loader, model, criterion, cuda='cuda' == 'cuda', bn_train_mode=False)\n",
    "\n",
    "#Grad distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=grad.cpu().numpy(), bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "\n",
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=torch.cat((checkpoint['state_dict']['layer.weight'].view(-1),checkpoint['state_dict']['layer.bias']),0).cpu().numpy(), bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
