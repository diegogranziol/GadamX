numpy imported
Preparing directory out/ImageNet32/WideResNet28x10/SSGDMN/seed=1_epoch_freq=10_curvaturesize=32_warmstart=-1_mom=0.0_wd=0.0001_numepochs=50/
Using model WideResNet28x10
Loading ImageNet32 from /jmain01/home/JAD017/sjr02/dxg49-sjr02/curvature/data/
You are going to run models on the test set. Are you sure?
Using train (1281167) + test (50000)
Preparing model
{'depth': 28, 'widen_factor': 10}
SGD training
Loading ImageNet32 from /jmain01/home/JAD017/sjr02/dxg49-sjr02/curvature/data/
You are going to run models on the test set. Are you sure?
Using train (32) + test (50000)
Iter 1. Time: 8.11
Iter 2. Time: 1.53
Iter 3. Time: 1.57
Iter 4. Time: 1.53
Iter 5. Time: 1.53
Iter 6. Time: 1.53
Iter 7. Time: 1.55
Iter 8. Time: 1.53
Iter 9. Time: 1.53
Iter 10. Time: 1.54
Iter 11. Time: 1.53
Iter 12. Time: 1.53
Iter 13. Time: 1.55
Iter 14. Time: 1.55
Iter 15. Time: 1.54
Iter 16. Time: 1.55
Iter 17. Time: 1.53
Iter 18. Time: 1.55
Iter 19. Time: 1.54
Iter 20. Time: 1.55
        value       weight
-------------  -----------
-158.229       7.79392e-10
-102.245       5.87136e-09
 -85.8995      9.03258e-08
 -82.5254      4.73025e-08
 -75.4123      1.1367e-07
 -69.6658      9.70838e-08
 -58.6047      1.41734e-07
  48.6015      8.20555e-09
 -47.7725      3.18352e-07
  43.0183      1.4497e-08
 -35.565       1.5489e-06
  32.8553      3.68447e-07
  28.5347      1.32438e-06
 -24.404       4.63262e-06
  21.0132      4.75084e-06
  13.21        2.61199e-05
 -12.5465      3.89878e-05
  -3.46662     0.00306725
   3.14087     0.00155422
   0.00518284  0.9953
[1.5822943e+02 1.0224497e+02 8.5899536e+01 8.2525368e+01 7.5412338e+01
 6.9665817e+01 5.8604713e+01 4.7772476e+01 3.5564968e+01 4.8601479e+01
 4.3018269e+01 2.4403955e+01 3.2855343e+01 2.8534712e+01 1.2546462e+01
 2.1013248e+01 3.4666245e+00 5.1828367e-03 3.1408703e+00 1.3210045e+01]
learning rate
0.14089038761368944
top
10.806677984308273
bottom
14.351178136779929
momentum
0.7530167824070394
----  --------  ---------  --------  ---------  --------  ---------  -----------
  ep        lr    tr_loss    tr_acc    te_loss    te_acc       time    mem_usage
----  --------  ---------  --------  ---------  --------  ---------  -----------
   1    0.1409     4.6168   13.8820     3.9691   20.5360  2631.8847       0.4185
   2    0.1409     3.2617   30.5187     3.8984   24.2360  2246.9914       0.4185
   3    0.1409     2.8600   37.2354     3.0816   34.0320  2244.4237       0.4185
   4    0.1409     2.6627   40.6790     3.2742   32.5760  2245.5728       0.4185
   5    0.1409     2.5468   42.8224     3.0206   36.6060  2243.0994       0.4185
   6    0.1409     2.4690   44.1870     2.9473   36.7900  2247.8412       0.4185
   7    0.1409     2.4162   45.1712     2.9143   38.0040  2239.7001       0.4185
   8    0.1409     2.3755   45.9421     2.9670   37.3280  2242.6131       0.4185
   9    0.1409     2.3459   46.4664     3.0014   36.8060  2239.3563       0.4185
  10    0.1409     2.3208   46.9014     2.7234   40.9140  2241.5386       0.4185
Iter 1. Time: 2.92
Iter 2. Time: 2.58
Iter 3. Time: 2.57
Iter 4. Time: 2.56
Iter 5. Time: 2.57
Iter 6. Time: 2.58
Iter 7. Time: 2.60
Iter 8. Time: 2.57
Iter 9. Time: 2.57
Iter 10. Time: 2.57
Iter 11. Time: 2.57
Iter 12. Time: 2.60
Iter 13. Time: 2.56
Iter 14. Time: 2.59
Iter 15. Time: 2.57
Iter 16. Time: 2.59
Iter 17. Time: 2.57
Iter 18. Time: 2.59
Iter 19. Time: 2.59
Iter 20. Time: 2.58
     value       weight
----------  -----------
32.6549     4.35377e-08
26.2194     2.17156e-08
21.783      2.16512e-08
17.4624     8.02208e-08
16.4939     1.06545e-08
14.9777     6.52452e-08
13.7116     8.64881e-08
11.5638     1.42767e-07
 9.6167     3.43286e-07
 7.66372    6.21748e-07
-7.48157    1.32709e-10
-5.54438    1.56772e-07
-5.06977    1.43181e-07
 4.98992    1.06735e-06
-3.91429    2.57359e-07
 2.71872    8.65669e-06
-1.71182    5.76684e-06
 0.941072   0.000628483
-0.0886628  0.0222429
 0.0014267  0.977111
[3.2654938e+01 2.6219439e+01 2.1783049e+01 7.4815660e+00 5.5443754e+00
 5.0697675e+00 3.9142878e+00 1.7118158e+00 1.4266997e-03 8.8662758e-02
 9.4107175e-01 2.7187202e+00 4.9899211e+00 7.6637244e+00 1.7462444e+01
 9.6166973e+00 1.6493946e+01 1.4977699e+01 1.3711645e+01 1.1563849e+01]
learning rate
0.05210701533183674
top
5.416686984134132
bottom
6.0122128306583
momentum
0.9009473111984024
  11    0.0521     2.2563   48.1451     2.6439   42.1520  2597.7958       0.4185
  12    0.0521     2.2446   48.3739     2.6961   41.3240  2243.1169       0.4185
  13    0.0521     2.2300   48.6554     2.5597   43.6940  2240.1009       0.4185
  14    0.0521     2.2158   48.9627     2.6286   42.5260  2239.7547       0.4185
  15    0.0521     2.2051   49.1624     2.6749   41.8180  2240.6408       0.4185
  16    0.0521     2.1979   49.2701     2.6874   42.4680  2242.1797       0.4185
  17    0.0521     2.1885   49.4382     2.6048   42.8220  2242.9237       0.4185
  18    0.0521     2.1800   49.6400     2.6342   42.7660  2236.9662       0.4185
  19    0.0521     2.1725   49.7596     2.5271   44.0960  2240.1005       0.4185
  20    0.0521     2.1668   49.8835     2.5057   44.4760  2239.3010       0.4185
Iter 1. Time: 4.40
Iter 2. Time: 2.56
Iter 3. Time: 2.58
Iter 4. Time: 2.56
Iter 5. Time: 2.57
Iter 6. Time: 2.59
Iter 7. Time: 2.58
Iter 8. Time: 2.56
Iter 9. Time: 2.57
Iter 10. Time: 2.58
Iter 11. Time: 2.56
Iter 12. Time: 2.58
Iter 13. Time: 2.57
Iter 14. Time: 2.59
Iter 15. Time: 2.57
Iter 16. Time: 2.59
Iter 17. Time: 2.58
Iter 18. Time: 2.56
Iter 19. Time: 2.57
Iter 20. Time: 2.58
      value       weight
-----------  -----------
35.0867      3.33797e-08
26.8305      3.16327e-09
21.8371      2.37779e-08
20.7918      4.19899e-08
19.1713      3.38715e-08
17.5582      5.51932e-08
14.9465      9.04137e-08
12.7544      1.64624e-07
10.8107      2.37195e-07
 8.65836     3.68027e-07
-7.26756     5.96851e-08
-6.25277     9.12972e-08
 5.79258     6.58265e-07
-5.64001     8.01006e-08
-3.88415     2.33542e-07
 3.24751     5.21892e-06
-1.80178     7.54346e-06
 1.07165     0.000415542
 0.077011    0.046364
-0.00418666  0.953205
[3.5086662e+01 2.6830469e+01 7.2675562e+00 6.2527714e+00 5.6400070e+00
 3.8841476e+00 1.8017837e+00 4.1866638e-03 7.7010997e-02 1.0716497e+00
 3.2475138e+00 2.1837061e+01 2.0791779e+01 1.9171333e+01 1.7558241e+01
 5.7925758e+00 1.4946460e+01 8.6583624e+00 1.2754357e+01 1.0810712e+01]
learning rate
0.04684954190345766
top
5.64589100299127
bottom
6.200908107735723
momentum
0.9104942219588675
  21    0.0468     2.1588   49.9843     2.5661   43.3280  2635.4378       0.4185
  22    0.0468     2.1551   50.1168     2.6050   43.2620  2238.3254       0.4185
  23    0.0468     2.1503   50.1836     2.5431   44.1860  2236.9141       0.4185
  24    0.0468     2.1455   50.3020     2.5151   44.5520  2234.9385       0.4185
  25    0.0468     2.1422   50.3417     2.5621   43.4460  2234.2730       0.4185
  26    0.0468     2.1367   50.5117     2.5730   43.9120  2235.7228       0.4185
  27    0.0468     2.1339   50.4525     2.4916   45.0060  2239.0466       0.4185
  28    0.0468     2.1293   50.5655     2.6862   42.2860  2233.6345       0.4185
  29    0.0468     2.1279   50.5885     2.5523   44.3720  2235.1069       0.4185
  30    0.0468     2.1252   50.7099     2.5766   44.1880  2235.1867       0.4185
Iter 1. Time: 4.18
Iter 2. Time: 2.53
Iter 3. Time: 2.57
Iter 4. Time: 2.55
Iter 5. Time: 2.55
Iter 6. Time: 2.74
Iter 7. Time: 2.56
Iter 8. Time: 2.57
Iter 9. Time: 2.54
Iter 10. Time: 2.56
Iter 11. Time: 2.55
Iter 12. Time: 2.56
Iter 13. Time: 2.55
Iter 14. Time: 2.57
Iter 15. Time: 2.55
Iter 16. Time: 2.57
Iter 17. Time: 2.55
Iter 18. Time: 2.57
Iter 19. Time: 2.54
Iter 20. Time: 2.57
       value       weight
------------  -----------
32.5511       3.32611e-10
28.3658       4.14283e-08
23.6847       2.79799e-09
22.4921       1.8747e-08
20.3469       1.159e-08
18.2162       4.37358e-08
16.3774       9.70805e-08
13.3853       4.21431e-07
11.4537       2.34661e-07
-9.1097       4.63407e-08
 8.9967       4.08195e-07
-7.2958       1.27183e-07
-6.0347       1.12831e-07
 5.94991      9.00425e-07
-4.54404      4.5385e-07
 2.97204      8.36912e-06
-2.44514      3.69177e-06
 0.832694     0.000909267
-0.338337     0.00216149
-2.67816e-05  0.996914
[3.2551125e+01 2.8365807e+01 2.3684696e+01 2.2492073e+01 2.0346876e+01
 9.1097002e+00 7.2958050e+00 6.0347013e+00 4.5440407e+00 2.4451354e+00
 2.6781603e-05 3.3833703e-01 8.3269447e-01 2.9720423e+00 5.9499121e+00
 1.8216208e+01 1.6377394e+01 8.9967022e+00 1.1453727e+01 1.3385283e+01]
learning rate
0.10195106672350515
top
5.12369182519012
bottom
6.287026745128562
momentum
0.8149626258803749
  31    0.1020     2.1527   50.1362     2.6430   42.3020  2614.6791       0.4185
  32    0.1020     2.1465   50.2692     2.7898   40.7380  2237.0115       0.4185
  33    0.1020     2.1449   50.2966     2.6837   41.5380  2233.4966       0.4185
  34    0.1020     2.1408   50.3575     2.8207   39.8560  2237.4832       0.4185
  35    0.1020     2.1402   50.3980     2.7831   40.8480  2232.7303       0.4185
  36    0.1020     2.1389   50.4426     2.5843   43.3740  2236.6700       0.4185
  37    0.1020     2.1374   50.4405     2.7298   40.9960  2232.2513       0.4185
  38    0.1020     2.1357   50.4200     2.6505   42.5260  2238.7611       0.4185
  39    0.1020     2.1348   50.4801     2.6667   43.2740  2230.9586       0.4185
  40    0.1020     2.1323   50.5690     2.5798   43.5820  2238.6256       0.4185
Iter 1. Time: 4.31
Iter 2. Time: 2.53
Iter 3. Time: 2.59
Iter 4. Time: 2.56
Iter 5. Time: 2.55
Iter 6. Time: 2.56
Iter 7. Time: 2.56
Iter 8. Time: 2.56
Iter 9. Time: 2.55
Iter 10. Time: 2.58
Iter 11. Time: 2.58
Iter 12. Time: 2.58
Iter 13. Time: 2.56
Iter 14. Time: 2.58
Iter 15. Time: 2.59
Iter 16. Time: 2.59
Iter 17. Time: 2.57
Iter 18. Time: 2.58
Iter 19. Time: 2.56
Iter 20. Time: 2.58
      value       weight
-----------  -----------
28.5233      3.49425e-10
23.8899      8.66028e-08
23.4655      5.66235e-09
22.1147      7.19394e-10
18.7718      6.11629e-08
17.9922      1.16001e-07
16.3006      7.55829e-08
13.3517      1.68551e-07
11.6879      2.09323e-07
 8.52138     2.73547e-07
-6.9331      5.4184e-08
 6.16487     7.15695e-07
-5.69889     2.60394e-08
-4.55802     1.41893e-07
 3.8077      3.27552e-06
-3.09419     4.36032e-07
 1.50296     0.000101038
-1.07921     3.85596e-05
 0.455135    0.00220874
-0.00110057  0.997646
[2.8523256e+01 2.3889896e+01 2.3465485e+01 2.2114740e+01 1.8771763e+01
 1.7992212e+01 1.6300602e+01 1.3351739e+01 1.1687865e+01 8.5213823e+00
 6.9331026e+00 6.1648664e+00 5.6988897e+00 4.5580196e+00 3.0941932e+00
 3.8077016e+00 1.0792139e+00 1.1005678e-03 4.5513457e-01 1.5029567e+00]
learning rate
0.1263194924249547
top
4.666080212933673
bottom
6.015353455236509
momentum
0.7756951021509366
----  --------  ---------  --------  ---------  --------  ---------  -----------
  ep        lr    tr_loss    tr_acc    te_loss    te_acc       time    mem_usage
----  --------  ---------  --------  ---------  --------  ---------  -----------
  41    0.1263     2.1443   50.3305     2.7588   40.6080  2603.2455       0.4185
  42    0.1263     2.1426   50.2968     2.6520   42.8940  2240.7673       0.4185
  43    0.1263     2.1396   50.4019     2.6468   42.3720  2230.7762       0.4185
  44    0.1263     2.1395   50.4211     2.8377   40.0880  2235.7950       0.4185
  45    0.1263     2.1380   50.4034     2.6460   42.2840  2231.6000       0.4185
  46    0.1263     2.1358   50.4785     2.6395   42.7840  2237.1234       0.4185
  47    0.1263     2.1349   50.4762     2.5571   44.0940  2231.9430       0.4185
  48    0.1263     2.1341   50.4908     2.6411   42.4140  2237.0487       0.4185
  49    0.1263     2.1327   50.5424     2.7212   41.4360  2230.3885       0.4185
  50    0.1263     2.1319   50.5766     2.6535   42.1280  2236.1998       0.4185
