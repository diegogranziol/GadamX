
	Python anaconda is now loaded in your environment.

Using model WideResNet28x10
Loading ImageNet32 from /jmain01/home/JAD017/sjr02/dxg49-sjr02/curvature/data/
You are going to run models on the test set. Are you sure?
Using train (1281167) + test (50000)
Loading ImageNet32 from /jmain01/home/JAD017/sjr02/dxg49-sjr02/curvature/data/
You are going to run models on the test set. Are you sure?
Using train (1281167) + test (50000)
Preparing model
{'depth': 28, 'widen_factor': 10}
Loading /jmain01/home/JAD017/sjr02/dxg49-sjr02/kfac-curvature/out/ImageNet32/WideResNet28x10/SGD/seed=1_lr=0.03_mom=0.9_wd=8e-06/checkpoint-00050.pt
Iter 1. Time: 11048.65
Iter 2. Time: 12230.92
Iter 3. Time: 12228.03
Iter 4. Time: 12232.78
Iter 5. Time: 12229.04
Iter 6. Time: 12223.81
Iter 7. Time: 12237.94
Iter 8. Time: 12234.23
Iter 9. Time: 12219.59
Iter 10. Time: 12222.88
Iter 11. Time: 12214.82
Iter 12. Time: 12242.80
Iter 13. Time: 12263.04
Iter 14. Time: 12208.87
Iter 15. Time: 12196.50
Iter 16. Time: 12192.60
Iter 17. Time: 12192.37
Iter 18. Time: 12195.44
Iter 19. Time: 12224.82
Iter 20. Time: 12231.70
Iter 21. Time: 12232.92
Iter 22. Time: 12228.35
Iter 23. Time: 12209.29
Iter 24. Time: 12181.75
Iter 25. Time: 12238.80
Iter 26. Time: 12301.53
Iter 27. Time: 12261.39
Iter 28. Time: 12256.59
Iter 29. Time: 12289.62
Iter 30. Time: 12254.11
Preparing directory /jmain01/home/JAD017/sjr02/dxg49-sjr02/kfac-curvature/out/ImageNet32/WideResNet28x10/SGD/seed=1_lr=0.03_mom=0.9_wd=8e-06/b=None_matrix=hessian/
hessian
       value       weight
------------  -----------
 8.72585      1.2919e-07
 6.82554      1.77844e-08
 4.74038      3.57461e-08
 3.98736      2.03759e-09
 3.39753      4.15231e-08
 3.12936      1.5239e-08
 2.97923      1.39118e-08
 2.8472       2.64736e-08
 2.54874      4.93924e-08
 2.3299       2.04732e-08
 2.04759      1.11686e-08
 1.84544      1.0911e-07
 1.71123      4.91687e-08
 1.53462      3.33754e-09
 1.22758      8.45926e-09
 1.0333       2.24669e-07
 0.924912     5.29323e-07
 0.698719     5.83426e-07
-0.686462     5.62973e-08
 0.554017     9.65859e-07
-0.534886     5.9583e-09
-0.473586     1.24044e-08
 0.389354     3.14894e-06
-0.385032     9.78167e-08
-0.296774     2.60638e-07
 0.254032     6.30452e-06
-0.17814      1.04601e-06
 0.112497     1.17781e-05
-0.0577957    1.97911e-05
 3.86132e-05  0.999955
